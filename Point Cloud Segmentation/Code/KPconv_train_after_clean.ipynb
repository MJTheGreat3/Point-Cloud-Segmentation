{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be48f895-a4e6-4531-ac97-a757a82d1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mIIITB_Base_train2_modified.ply\u001b[0m*  \u001b[01;32mpart_a1_modified.ply\u001b[0m*  \u001b[01;32mreclassify_barriers.sh\u001b[0m*\n",
      "\u001b[01;32mcoarse_classes.xml\u001b[0m*              \u001b[01;32mpart_a2_modified.ply\u001b[0m*\n",
      "\u001b[01;32mcol_drop.sh\u001b[0m*                     \u001b[01;32mpart_a3_modified.ply\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls Open3D-ML/ml3d/datasets/Paris/training_10_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751e4769-9637-4498-99be-d5d4c5527259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: Manual/A1-A10_ongoing6.ply\n",
      "Writing to: Open3D-ML/ml3d/datasets/Paris/training_10_classes/A1-A10_ongoing7.ply\n",
      "Removing points where scalar_Classification is 12.0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m OUTPUT_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen3D-ML/ml3d/datasets/Paris/training_10_classes/A1-A10_ongoing7.ply\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Run the function\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[43mfilter_and_retype_ply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_to_remove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mfilter_and_retype_ply\u001b[0;34m(input_filename, output_filename, value_to_remove)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# --- 1. Read and Process the Input File ---\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m infile:\n\u001b[1;32m     31\u001b[0m             line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line: \u001b[38;5;66;03m# Skip empty lines\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/KPConvEnvMatt/lib/python3.10/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def filter_and_retype_ply(input_filename, output_filename, value_to_remove=12.0):\n",
    "    \"\"\"\n",
    "    Reads an ASCII PLY file, removes points with a specific \n",
    "    'scalar_Classification' value, and changes the property type \n",
    "    in the header from float to int.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Reading from: {input_filename}\")\n",
    "    print(f\"Writing to: {output_filename}\")\n",
    "    print(f\"Removing points where scalar_Classification is {value_to_remove}...\")\n",
    "    \n",
    "    if not os.path.exists(input_filename):\n",
    "        print(f\"Error: Input file not found at '{input_filename}'\")\n",
    "        return\n",
    "\n",
    "    # Indices assumed from your header structure:\n",
    "    # x: 0, y: 1, z: 2, scalar_Classification: 3, scalar_Original_cloud_index: 4\n",
    "    CLASSIFICATION_INDEX = 3\n",
    "    \n",
    "    header_lines = []\n",
    "    vertex_data_lines = []\n",
    "    in_header = True\n",
    "    original_vertex_count = 0\n",
    "    \n",
    "    try:\n",
    "        # --- 1. Read and Process the Input File ---\n",
    "        with open(input_filename, 'r') as infile:\n",
    "            for line in infile:\n",
    "                line = line.strip()\n",
    "                if not line: # Skip empty lines\n",
    "                    continue\n",
    "                \n",
    "                if in_header:\n",
    "                    header_lines.append(line)\n",
    "                    if line == 'end_header':\n",
    "                        in_header = False\n",
    "                else:\n",
    "                    original_vertex_count += 1\n",
    "                    parts = line.split()\n",
    "                    \n",
    "                    if len(parts) > CLASSIFICATION_INDEX:\n",
    "                        try:\n",
    "                            current_classification = float(parts[CLASSIFICATION_INDEX])\n",
    "                            \n",
    "                            # --- Filter Step: Keep only if classification is NOT the value to remove ---\n",
    "                            if current_classification != value_to_remove:\n",
    "                                # --- Retype Step: Change classification to int format for writing ---\n",
    "                                parts[CLASSIFICATION_INDEX] = str(int(current_classification))\n",
    "                                vertex_data_lines.append(' '.join(parts))\n",
    "                                \n",
    "                        except ValueError:\n",
    "                            # If parsing fails, treat it as non-vertex data and skip filtering/retyping\n",
    "                            vertex_data_lines.append(line)\n",
    "                    else:\n",
    "                        # Keep lines that aren't long enough to be standard vertex data\n",
    "                        vertex_data_lines.append(line)\n",
    "\n",
    "\n",
    "        # --- 2. Modify Header and Prepare Output ---\n",
    "        modified_header = []\n",
    "        new_vertex_count = len(vertex_data_lines)\n",
    "        \n",
    "        for line in header_lines:\n",
    "            if line.startswith('element vertex'):\n",
    "                # Update the vertex count\n",
    "                modified_header.append(f'element vertex {new_vertex_count}')\n",
    "            elif line.startswith('property float scalar_Classification'):\n",
    "                # Change the type from float to int\n",
    "                modified_header.append('property int scalar_Classification')\n",
    "            else:\n",
    "                # Keep other header lines as they are\n",
    "                modified_header.append(line)\n",
    "\n",
    "        # --- 3. Write the Output File ---\n",
    "        with open(output_filename, 'w') as outfile:\n",
    "            # Write the modified header\n",
    "            outfile.write('\\n'.join(modified_header) + '\\n')\n",
    "            \n",
    "            # Write the filtered and retyped vertex data\n",
    "            outfile.write('\\n'.join(vertex_data_lines) + '\\n')\n",
    "\n",
    "        # --- 4. Summary ---\n",
    "        points_removed = original_vertex_count - new_vertex_count\n",
    "        \n",
    "        print(\"-\" * 45)\n",
    "        print(f\"✅ Processing complete!\")\n",
    "        print(f\"Original points: {original_vertex_count}\")\n",
    "        print(f\"Points removed (Classification=12.0): **{points_removed}**\")\n",
    "        print(f\"Final points count: {new_vertex_count}\")\n",
    "        print(f\"New file saved as: **{output_filename}**\")\n",
    "        print(\"Note: scalar_Classification property type is now 'int' in the header.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# IMPORTANT: Change 'input.ply' to the actual name of your file\n",
    "INPUT_FILE = 'Manual/A1-A10_ongoing6.ply' \n",
    "OUTPUT_FILE = 'Open3D-ML/ml3d/datasets/Paris/training_10_classes/A1-A10_ongoing7.ply' \n",
    "\n",
    "# Run the function\n",
    "filter_and_retype_ply(INPUT_FILE, OUTPUT_FILE, value_to_remove=12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80291cb2-61de-437b-983f-aa2164743f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d.ml as _ml3d\n",
    "import open3d as o3d\n",
    "import open3d.ml.torch as ml3d\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b544f0a-ce38-476f-aab3-0f7ce3a27248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f31573-5e2b-45d0-91d0-c656d7f7a82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ccbc59b-45c0-4d07-920d-cf6c00d8e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84cc17b3-5680-4127-ba1e-8c5dee4af7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda15865-6348-4714-ab71-cd0b6e158ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = r\"/mnt/e/PE/Mathew/Codes/Partitions/Open3D-ML/ml3d/configs/kpconv_parislille3d_mod.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = ml3d.models.KPFCNN(**cfg.model)\n",
    "cfg.dataset['dataset_path'] = r\"/mnt/e/PE/Mathew/Codes/Partitions/Open3D-ML/ml3d/datasets/Paris\"\n",
    "dataset = ml3d.datasets.ParisLille3D(cfg.dataset.pop('dataset_path', None), **cfg.dataset)\n",
    "pipeline = ml3d.pipelines.SemanticSegmentation(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3881a089-7418-429f-9945-e5b1769c1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_folder = \"./logs/\"\n",
    "os.makedirs(ckpt_folder, exist_ok=True)\n",
    "ckpt_path = ckpt_folder + \"kpconv_parislille3d_202011241550utc_mod.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f5cde3-be1e-4a20-9de8-edd7db741088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parameters.\n",
    "# pipeline.load_ckpt(ckpt_path=ckpt_path)\n",
    "pipeline.load_ckpt(ckpt_path=ckpt_path, is_resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660921dc-9e7b-496f-a61f-b4caf6f1034e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/e/PE/Mathew/Codes/Partitions/Open3D-ML/ml3d/datasets/Paris/training_10_classes/part_a1_modified.ply',\n",
       " '/mnt/e/PE/Mathew/Codes/Partitions/Open3D-ML/ml3d/datasets/Paris/training_10_classes/part_a2_modified.ply',\n",
       " '/mnt/e/PE/Mathew/Codes/Partitions/Open3D-ML/ml3d/datasets/Paris/training_10_classes/part_a3_modified.ply']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_split_list(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254f123c-58c6-401a-93cd-fa12a2de43c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = dataset.get_split(\"train\")\n",
    "len(train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27397e1f-0393-4d64-80e1-ff006d654049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [19:03<00:00, 22.86s/it]\n",
      "validation: 100%|███████████████████████████████████████████████████████████████████████| 15/15 [02:27<00:00,  9.84s/it]\n",
      "training: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [18:45<00:00, 22.51s/it]\n",
      "validation: 100%|███████████████████████████████████████████████████████████████████████| 15/15 [02:17<00:00,  9.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 27min 58s, sys: 6min 12s, total: 1h 34min 10s\n",
      "Wall time: 42min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.cfg.num_workers = 0\n",
    "pipeline.cfg.pin_memory = False\n",
    "pipeline.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6cf1ca-7d94-4cbf-8f8c-358cc0328972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
