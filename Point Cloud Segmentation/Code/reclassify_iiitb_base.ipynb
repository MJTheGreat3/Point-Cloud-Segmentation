{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201ce539-9d60-40ea-9edd-91dbd3de2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classification values BEFORE processing:\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 9.0, 55.0]\n",
      "\n",
      "Unique classification values AFTER processing:\n",
      "[0.0, 1.0, 2.0, 8.0]\n",
      "\n",
      "Filtered PLY written to: IIITB_Base_train.ply\n",
      "Remaining points: 2179723\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_ply_ascii(filepath):\n",
    "    \"\"\"\n",
    "    Reads an ASCII PLY file and returns the header lines and a pandas DataFrame\n",
    "    of the vertex data.\n",
    "    \"\"\"\n",
    "    header = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        # Read header until 'end_header'\n",
    "        for line in f:\n",
    "            header.append(line.rstrip())\n",
    "            if line.strip() == 'end_header':\n",
    "                break\n",
    "        \n",
    "        # The remaining lines are the data\n",
    "        data = [list(map(float, line.split())) for line in f if line.strip()]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=['x', 'y', 'z', 'scalar_Classification'])\n",
    "    return header, df\n",
    "\n",
    "\n",
    "def process_classifications(df):\n",
    "    \"\"\"\n",
    "    Removes unwanted classifications and applies remapping rules.\n",
    "    Returns filtered + remapped DataFrame and unique value sets before and after.\n",
    "    \"\"\"\n",
    "    # Distinct before\n",
    "    unique_before = sorted(df['scalar_Classification'].unique())\n",
    "\n",
    "    # Remove unwanted classifications\n",
    "    remove_classes = {0.0, 7.0, 9.0, 55.0}\n",
    "    df = df[~df['scalar_Classification'].isin(remove_classes)].copy()\n",
    "\n",
    "    # Apply mapping\n",
    "    mapping = {\n",
    "        1.0: 0.0,\n",
    "        2.0: 2.0, 3.0: 2.0,\n",
    "        4.0: 8.0, 6.0: 8.0,\n",
    "        5.0: 1.0\n",
    "    }\n",
    "    df['scalar_Classification'] = df['scalar_Classification'].replace(mapping)\n",
    "\n",
    "    # Distinct after\n",
    "    unique_after = sorted(df['scalar_Classification'].unique())\n",
    "    return df, unique_before, unique_after\n",
    "\n",
    "\n",
    "def write_ply_ascii(filepath, header, df):\n",
    "    \"\"\"\n",
    "    Writes the filtered and modified point cloud back to an ASCII PLY file.\n",
    "    Updates vertex count in the header.\n",
    "    \"\"\"\n",
    "    # Update vertex count line\n",
    "    new_header = []\n",
    "    for line in header:\n",
    "        if line.startswith('element vertex'):\n",
    "            new_header.append(f'element vertex {len(df)}')\n",
    "        else:\n",
    "            new_header.append(line)\n",
    "    \n",
    "    # Write back to file\n",
    "    with open(filepath, 'w') as f:\n",
    "        for line in new_header:\n",
    "            f.write(line + '\\n')\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f\"{row.x:.6f} {row.y:.6f} {row.z:.6f} {row.scalar_Classification:.6f}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_ply = 'IIITB_Base.ply'   # Change this to your file path\n",
    "    output_ply = 'IIITB_Base_train.ply'\n",
    "\n",
    "    header, df = read_ply_ascii(input_ply)\n",
    "    processed_df, unique_before, unique_after = process_classifications(df)\n",
    "\n",
    "    print(\"Unique classification values BEFORE processing:\")\n",
    "    print(unique_before)\n",
    "    print(\"\\nUnique classification values AFTER processing:\")\n",
    "    print(unique_after)\n",
    "\n",
    "    write_ply_ascii(output_ply, header, processed_df)\n",
    "    print(f\"\\nFiltered PLY written to: {output_ply}\")\n",
    "    print(f\"Remaining points: {len(processed_df)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b727ce8-3833-41a5-905c-5114818bb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class_field(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # Identify the header and the start of vertex data\n",
    "    header_end = lines.index('end_header\\n') + 1\n",
    "    vertex_lines = lines[header_end:]\n",
    "\n",
    "    # Update the class field (4th field in each vertex line)\n",
    "    updated_vertex_lines = []\n",
    "    for line in vertex_lines:\n",
    "        # Split the line into components (x, y, z, class)\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 4:\n",
    "            # Convert the class field to int\n",
    "            parts[3] = str(int(float(parts[3])))  # Convert class field from float to int\n",
    "        # Join the parts back into a single line\n",
    "        updated_vertex_lines.append(\" \".join(parts))\n",
    "        updated_vertex_lines.append(\"\\n\")\n",
    "\n",
    "    # Write the updated content back to a new file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        # Write the header and updated vertex data\n",
    "        outfile.writelines(lines[:header_end])  # Write header\n",
    "        outfile.writelines(updated_vertex_lines)  # Write updated vertex lines\n",
    "\n",
    "# Usage\n",
    "input_file = 'IIITB_Base_train.ply'  # Replace with your input PLY file path\n",
    "output_file = 'IIITB_Base_train2.ply' # Replace with the desired output PLY file path\n",
    "\n",
    "convert_class_field(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e5598-0dda-4e4a-bc61-f7b9002f16a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
