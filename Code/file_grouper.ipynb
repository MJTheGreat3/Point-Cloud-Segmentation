{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11eec58f-1721-4113-9ea1-f51a9740be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2311e16a-dc59-4fc9-a1ca-7725cb0f1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ply(file_name):\n",
    "    vertices = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        header_end = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip() == 'end_header':\n",
    "                header_end = i + 1\n",
    "                break\n",
    "        vertex_lines = lines[header_end:]\n",
    "        for line in vertex_lines:\n",
    "            parts = line.split()\n",
    "            x, y, z = map(float, parts[:3])  # x, y, z coordinates\n",
    "            vertices.append((x, y, z))\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81457537-2223-47a8-bb6e-44fa1d6b1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(file_name, vertices, block_id):\n",
    "    # Start writing the header\n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write('ply\\n')\n",
    "        file.write('format ascii 1.0\\n')\n",
    "        file.write(f'element vertex {len(vertices)}\\n')\n",
    "        file.write('property float x\\n')\n",
    "        file.write('property float y\\n')\n",
    "        file.write('property float z\\n')\n",
    "        file.write('property float scalar_intensity\\n')\n",
    "        file.write('property float scalar_blockid\\n')\n",
    "        file.write('end_header\\n')\n",
    "\n",
    "        # Write the vertices with the new properties\n",
    "        for (x, y, z) in vertices:\n",
    "            file.write(f'{x} {y} {z} 1 {block_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef602118-d070-494f-98d3-96b7872b2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped PLY files have been written to the directory: grouped_ply_files\n",
      "Grouped PLY files have been written to the directory: grouped_ply_files\n",
      "Grouped PLY files have been written to the directory: grouped_ply_files\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\"partition_summary_Campus_BlockBa.csv\",  \"partition_summary_Campus_BlockBb.csv\",  \"partition_summary_Campus_BlockBc.csv\"]\n",
    "for csv_file in csv_files:\n",
    "    suffix = csv_file[-5:-4]\n",
    "    df = pd.read_csv(csv_file)\n",
    "    grouped_files = []\n",
    "    current_group = []\n",
    "    current_size = 0\n",
    "    \n",
    "    # Block ID counter\n",
    "    block_id_counter = 1\n",
    "    \n",
    "    # Iterate through the CSV rows to group by file size under 1 GB\n",
    "    for _, row in df.iterrows():\n",
    "        block_id = row['Block_ID']\n",
    "        file_name = row['File_Name']\n",
    "        size_mb = row['Size_MB']\n",
    "    \n",
    "        if current_size + size_mb <= 1024:  # If the cumulative size is less than 1GB\n",
    "            current_group.append(file_name)\n",
    "            current_size += size_mb\n",
    "        else:\n",
    "            # Process the current group of files\n",
    "            grouped_files.append(current_group)\n",
    "            \n",
    "            # Reset the current group and size for the next one\n",
    "            current_group = [file_name]\n",
    "            current_size = size_mb\n",
    "    \n",
    "    # Don't forget to add the last group\n",
    "    if current_group:\n",
    "        grouped_files.append(current_group)\n",
    "    \n",
    "    # Step 5: Process each group of files\n",
    "    output_dir = 'grouped_ply_files'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for group in grouped_files:\n",
    "        all_vertices = []\n",
    "        \n",
    "        # Read all the PLY files in the current group and accumulate vertices\n",
    "        for file_name in group:\n",
    "            ply_vertices = read_ply(file_name)\n",
    "            all_vertices.extend(ply_vertices)\n",
    "    \n",
    "        # Remove duplicates based on x, y, z\n",
    "        unique_vertices = list(set(all_vertices))  # Remove duplicate vertices based on x, y, z\n",
    "    \n",
    "        # Step 6: Write the unique vertices to a new PLY file with a new Block ID\n",
    "        new_file_name = os.path.join(output_dir, f\"Campus_BlockB{suffix}_group_{block_id_counter}.ply\")\n",
    "        write_ply(new_file_name, unique_vertices, block_id_counter)\n",
    "        \n",
    "        # Increment the block ID counter for the next file group\n",
    "        block_id_counter += 1\n",
    "    \n",
    "    print(f\"Grouped PLY files have been written to the directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464c129-430a-4a0c-bb9f-d79e248cffb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
